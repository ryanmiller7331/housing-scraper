{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a93f2b-5cbc-4a0f-a1bc-ab7c1dcf5047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This script is a web scraper used to assist cleaning and standardizing city and zip code data. The URL is a \n",
    "direct postal reference for zip codes in Allegheny County, Pennsylvania and their respective towns/cities associated\n",
    "to that zip. \n",
    "\n",
    "I was able to merge this script's resulting dataframe with the data I had collected to stadardize city names \n",
    "(ex: East Pittsburgh and E Pittsburgh should both be under East Pittsburgh, some values show Bradford Woods \n",
    "while others show Bradfordwoods, etc.) \n",
    "'''\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Scraped website\n",
    "url = 'https://www.zipdatamaps.com/en/us/zip-maps/pa/county/borders/allegheny-county-zip-code-map'\n",
    "\n",
    "# HTTP GET request, stored in 'page'\n",
    "page = requests.get(url)\n",
    "\n",
    "# Beautifulsoup object to parse the HTML content\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# HTML table with the data I'm looking for \n",
    "table = soup.find('table', class_='table')\n",
    "\n",
    "# List to store extracted data\n",
    "data = []\n",
    "\n",
    "# Pulling rows ('tr')\n",
    "column_data = table.find_all('tr')\n",
    "\n",
    "# Loop through each row in the table\n",
    "for row in column_data:\n",
    "    # Pulling column values ('td') in each section of current row\n",
    "    row_data = row.find_all('td')\n",
    "    \n",
    "    '''\n",
    "    As for the indented lines below, I encountered an issue where there were empty values in cells in each of \n",
    "    the rows of the data. The info I was looking for was in 1st and 5th positions on the row, so below is how\n",
    "    I navigated this: \n",
    "    '''\n",
    "    \n",
    "    # Checking row for expected number of columns\n",
    "    if len(row_data) == 5:\n",
    "        # Pull zip code/city name from the 1st/5th column, then stripping whitespace\n",
    "        zip_code = row_data[0].text.strip()\n",
    "        city_name = row_data[4].text.strip()\n",
    "        \n",
    "        # Appending zip code and city name to the 'data' list\n",
    "        data.append([zip_code, city_name])\n",
    "\n",
    "# Setting dataframe with the collected data, with column names\n",
    "df = pd.DataFrame(data, columns=[\"Zip Code\", \"City Name\"])\n",
    "\n",
    "# Saving as a CSV\n",
    "df.to_csv('C:/Users/ryanm/Desktop/Projects/3/Datasets/zip_city_check.csv', index=False)\n",
    "print(\"Scraped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
